pf_weight_sum_normalized = portfolio_df['pf_weights'].sum()
print(f'Suma wag po normalizacji: {pf_weight_sum_normalized:.2f}')  # Sprawdzenie sumy wag po normalizacji
# Wyświetlenie przykładowych danych po normalizacji
portfolio_df.head(10)
# Tworzenie przykładowych danych
data = {
'mean_return': [0.146, 0.444, 0.242, 0.225, 0.183, 0.176, 0.072, 0.172, 0.186, 0.151],
'variance': [0.035, 0.094, 0.030, 0.027, 0.030, 0.018, 0.014, 0.020, 0.032, 0.026],
'pf_weights': [0.10, 0.05, 0.15, 0.10, 0.05, 0.20, 0.10, 0.05, 0.10, 0.10],  # Przykładowe wagi
'bm_weights': [0.10, 0.05, 0.15, 0.10, 0.05, 0.20, 0.10, 0.05, 0.10, 0.10],  # Przykładowe wagi benchmarku
'Security': [
'Agilent Technologies Inc', 'American Airlines Group', 'Advance Auto Parts',
'Apple Inc.', 'AbbVie', 'AmerisourceBergen Corp', 'Abbott Laboratories',
'Accenture plc', 'Adobe Systems Inc', 'Analog Devices, Inc.'
],
'GICS Sector': [
'Health Care', 'Industrials', 'Consumer Discretionary', 'Information Technology',
'Health Care', 'Health Care', 'Health Care', 'Information Technology',
'Information Technology', 'Information Technology'
],
'GICS Sub Industry': [
'Health Care Equipment', 'Airlines', 'Automotive Retail', 'Computer Hardware',
'Pharmaceuticals', 'Health Care Distributors', 'Health Care Equipment',
'IT Consulting & Other Services', 'Application Software', 'Semiconductors'
]
}
# Tworzenie DataFrame
portfolio_df = pd.DataFrame(data)
portfolio_df.index = ['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACN', 'ADBE', 'ADI']
# Sprawdzenie sumy wag portfela
pf_weight_sum = portfolio_df['pf_weights'].sum()
print(f'Suma wag portfela: {pf_weight_sum:.2f}')  # Sprawdzenie sumy wag
# Normalizacja wag do sumy 1 (100%)
portfolio_df['pf_weights'] = portfolio_df['pf_weights'] / pf_weight_sum
# Sprawdzenie sumy wag po normalizacji
pf_weight_sum_normalized = portfolio_df['pf_weights'].sum()
print(f'Suma wag po normalizacji: {pf_weight_sum_normalized:.2f}')  # Sprawdzenie sumy wag po normalizacji
# Wyświetlenie przykładowych danych po normalizacji
portfolio_df.head(10)
# Tworzenie przykładowych danych
data = {
'mean_return': [0.146, 0.444, 0.242, 0.225, 0.183, 0.176, 0.072, 0.172, 0.186, 0.151],
'variance': [0.035, 0.094, 0.030, 0.027, 0.030, 0.018, 0.014, 0.020, 0.032, 0.026],
'pf_weights': [0.10, 0.05, 0.15, 0.10, 0.05, 0.20, 0.10, 0.05, 0.10, 0.10],  # Przykładowe wagi
'bm_weights': [0.10, 0.05, 0.15, 0.10, 0.05, 0.20, 0.10, 0.05, 0.10, 0.10],  # Przykładowe wagi benchmarku
'Security': [
'Agilent Technologies Inc', 'American Airlines Group', 'Advance Auto Parts',
'Apple Inc.', 'AbbVie', 'AmerisourceBergen Corp', 'Abbott Laboratories',
'Accenture plc', 'Adobe Systems Inc', 'Analog Devices, Inc.'
],
'GICS Sector': [
'Health Care', 'Industrials', 'Consumer Discretionary', 'Information Technology',
'Health Care', 'Health Care', 'Health Care', 'Information Technology',
'Information Technology', 'Information Technology'
],
'GICS Sub Industry': [
'Health Care Equipment', 'Airlines', 'Automotive Retail', 'Computer Hardware',
'Pharmaceuticals', 'Health Care Distributors', 'Health Care Equipment',
'IT Consulting & Other Services', 'Application Software', 'Semiconductors'
]
}
# Tworzenie DataFrame
portfolio_df = pd.DataFrame(data)
portfolio_df.index = ['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACN', 'ADBE', 'ADI']
# Sprawdzenie sumy wag portfela
pf_weight_sum = portfolio_df['pf_weights'].sum()
print(f'Suma wag portfela: {pf_weight_sum:.2f}')  # Sprawdzenie sumy wag
# Normalizacja wag do sumy 1 (100%)
portfolio_df['pf_weights'] = portfolio_df['pf_weights'] / pf_weight_sum
# Sprawdzenie sumy wag po normalizacji
pf_weight_sum_normalized = portfolio_df['pf_weights'].sum()
print(f'Suma wag po normalizacji: {pf_weight_sum_normalized:.2f}')  # Sprawdzenie sumy wag po normalizacji
# Wyświetlenie przykładowych danych po normalizacji
portfolio_df.head(10)
print(portfolio_data.pf_weights.sum())
#| echo: false
#| include: false
# Tworzenie przykładowych danych
data = {
'mean_return': [0.146, 0.444, 0.242, 0.225, 0.183, 0.176, 0.072, 0.172, 0.186, 0.151],
'variance': [0.035, 0.094, 0.030, 0.027, 0.030, 0.018, 0.014, 0.020, 0.032, 0.026],
'pf_weights': [0.10, 0.05, 0.15, 0.10, 0.05, 0.20, 0.10, 0.05, 0.10, 0.10],  # Przykładowe wagi
'bm_weights': [0.10, 0.05, 0.15, 0.10, 0.05, 0.20, 0.10, 0.05, 0.10, 0.10],  # Przykładowe wagi benchmarku
'Security': [
'Agilent Technologies Inc', 'American Airlines Group', 'Advance Auto Parts',
'Apple Inc.', 'AbbVie', 'AmerisourceBergen Corp', 'Abbott Laboratories',
'Accenture plc', 'Adobe Systems Inc', 'Analog Devices, Inc.'
],
'GICS Sector': [
'Health Care', 'Industrials', 'Consumer Discretionary', 'Information Technology',
'Health Care', 'Health Care', 'Health Care', 'Information Technology',
'Information Technology', 'Information Technology'
],
'GICS Sub Industry': [
'Health Care Equipment', 'Airlines', 'Automotive Retail', 'Computer Hardware',
'Pharmaceuticals', 'Health Care Distributors', 'Health Care Equipment',
'IT Consulting & Other Services', 'Application Software', 'Semiconductors'
]
}
# Tworzenie DataFrame
portfolio_data = pd.DataFrame(data)
portfolio_data.index = ['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACN', 'ADBE', 'ADI']
# Wyświetlenie przykładowych danych po normalizacji
portfolio_data.head(10)
print(portfolio_data.pf_weights.sum())
total_return_pf = (portfolio_data['pf_weights']*portfolio_data['mean_return']).sum()
active_return = total_return_pf - total_return_bm
print ("%.2f%%" % active_return)
total_return_pf = (portfolio_data['pf_weights']*portfolio_data['mean_return']).sum()
total_return_bm = (portfolio_data['bm_weights']*portfolio_data['mean_return']).sum()
active_return = total_return_pf - total_return_bm
print ("%.2f%%" % active_return)
print(portfolio_data.pf_weights.sum())
total_return_pf = (portfolio_data['pf_weights']*portfolio_data['mean_return']).sum()
total_return_bm = (portfolio_data['bm_weights']*portfolio_data['mean_return']).sum()
active_return = total_return_pf - total_return_bm
print ("%.2f%%" % active_return)
#| echo: false
#| include: false
# Tworzenie przykładowych danych
data = {
'mean_return': [0.146, 0.444, 0.242, 0.225, 0.183, 0.176, 0.072, 0.172, 0.186, 0.151],
'variance': [0.035, 0.094, 0.030, 0.027, 0.030, 0.018, 0.014, 0.020, 0.032, 0.026],
'pf_weights': [0.10, 0.05, 0.20, 0.15, 0.10, 0.10, 0.05, 0.05, 0.10, 0.10],  # Zmienione wagi portfela
'bm_weights': [0.12, 0.08, 0.12, 0.10, 0.08, 0.18, 0.08, 0.08, 0.08, 0.08],  # Zmienione wagi benchmarku
'Security': [
'Agilent Technologies Inc', 'American Airlines Group', 'Advance Auto Parts',
'Apple Inc.', 'AbbVie', 'AmerisourceBergen Corp', 'Abbott Laboratories',
'Accenture plc', 'Adobe Systems Inc', 'Analog Devices, Inc.'
],
'GICS Sector': [
'Health Care', 'Industrials', 'Consumer Discretionary', 'Information Technology',
'Health Care', 'Health Care', 'Health Care', 'Information Technology',
'Information Technology', 'Information Technology'
],
'GICS Sub Industry': [
'Health Care Equipment', 'Airlines', 'Automotive Retail', 'Computer Hardware',
'Pharmaceuticals', 'Health Care Distributors', 'Health Care Equipment',
'IT Consulting & Other Services', 'Application Software', 'Semiconductors'
]
}
# Tworzenie DataFrame
portfolio_data = pd.DataFrame(data)
portfolio_data.index = ['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACN', 'ADBE', 'ADI']
# Wyświetlenie przykładowych danych po normalizacji
portfolio_data.head(10)
print(portfolio_data.pf_weights.sum())
total_return_pf = (portfolio_data['pf_weights']*portfolio_data['mean_return']).sum()
total_return_bm = (portfolio_data['bm_weights']*portfolio_data['mean_return']).sum()
active_return = total_return_pf - total_return_bm
print ("%.2f%%" % active_return)
#| echo: false
#| include: false
# Tworzenie przykładowych danych
data = {
'mean_return': [0.146, 0.444, 0.242, 0.225, 0.183, 0.176, 0.072, 0.172, 0.186, 0.151],
'variance': [0.035, 0.094, 0.030, 0.027, 0.030, 0.018, 0.014, 0.020, 0.032, 0.026],
'pf_weights': [0.15, 0.05, 0.20, 0.10, 0.05, 0.10, 0.05, 0.10, 0.10, 0.10],  # Zmienione wagi portfela
'bm_weights': [0.10, 0.10, 0.10, 0.10, 0.15, 0.10, 0.10, 0.05, 0.10, 0.10],  # Zmienione wagi benchmarku
'Security': [
'Agilent Technologies Inc', 'American Airlines Group', 'Advance Auto Parts',
'Apple Inc.', 'AbbVie', 'AmerisourceBergen Corp', 'Abbott Laboratories',
'Accenture plc', 'Adobe Systems Inc', 'Analog Devices, Inc.'
],
'GICS Sector': [
'Health Care', 'Industrials', 'Consumer Discretionary', 'Information Technology',
'Health Care', 'Health Care', 'Health Care', 'Information Technology',
'Information Technology', 'Information Technology'
],
'GICS Sub Industry': [
'Health Care Equipment', 'Airlines', 'Automotive Retail', 'Computer Hardware',
'Pharmaceuticals', 'Health Care Distributors', 'Health Care Equipment',
'IT Consulting & Other Services', 'Application Software', 'Semiconductors'
]
}
# Tworzenie DataFrame
portfolio_data = pd.DataFrame(data)
portfolio_data.index = ['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACN', 'ADBE', 'ADI']
# Wyświetlenie przykładowych danych po normalizacji
portfolio_data.head(10)
print(portfolio_data.pf_weights.sum())
total_return_pf = (portfolio_data['pf_weights']*portfolio_data['mean_return']).sum()
total_return_bm = (portfolio_data['bm_weights']*portfolio_data['mean_return']).sum()
active_return = total_return_pf - total_return_bm
print ("%.2f%%" % active_return)
View(active_return)
#| echo: false
#| include: false
# Tworzenie przykładowych danych
data = {
'mean_return': [0.146, 0.444, 0.242, 0.225, 0.183, 0.176, 0.072, 0.172, 0.186, 0.151],
'variance': [0.035, 0.094, 0.030, 0.027, 0.030, 0.018, 0.014, 0.020, 0.032, 0.026],
'pf_weights': [0.20, 0.05, 0.10, 0.10, 0.05, 0.15, 0.10, 0.05, 0.10, 0.10],  # Zmienione wagi portfela
'bm_weights': [0.10, 0.10, 0.10, 0.10, 0.15, 0.10, 0.10, 0.10, 0.05, 0.05],  # Zmienione wagi benchmarku
'Security': [
'Agilent Technologies Inc', 'American Airlines Group', 'Advance Auto Parts',
'Apple Inc.', 'AbbVie', 'AmerisourceBergen Corp', 'Abbott Laboratories',
'Accenture plc', 'Adobe Systems Inc', 'Analog Devices, Inc.'
],
'GICS Sector': [
'Health Care', 'Industrials', 'Consumer Discretionary', 'Information Technology',
'Health Care', 'Health Care', 'Health Care', 'Information Technology',
'Information Technology', 'Information Technology'
],
'GICS Sub Industry': [
'Health Care Equipment', 'Airlines', 'Automotive Retail', 'Computer Hardware',
'Pharmaceuticals', 'Health Care Distributors', 'Health Care Equipment',
'IT Consulting & Other Services', 'Application Software', 'Semiconductors'
]
}
# Tworzenie DataFrame
portfolio_data = pd.DataFrame(data)
portfolio_data.index = ['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACN', 'ADBE', 'ADI']
# Wyświetlenie przykładowych danych po normalizacji
portfolio_data.head(10)
print(portfolio_data.pf_weights.sum())
total_return_pf = (portfolio_data['pf_weights']*portfolio_data['mean_return']).sum()
total_return_bm = (portfolio_data['bm_weights']*portfolio_data['mean_return']).sum()
active_return = total_return_pf - total_return_bm
print ("%.2f%%" % active_return)
View(data)
portfolio_data = pd.read_csv('large_pf.csv')
print(portfolio_data.pf_weights.sum())
total_return_pf = (portfolio_data['pf_weights']*portfolio_data['mean_return']).sum()
total_return_bm = (portfolio_data['bm_weights']*portfolio_data['mean_return']).sum()
active_return = total_return_pf - total_return_bm
print ("%.2f%%" % active_return)
#| include: true
#| echo: true
grouped_df=portfolio_data.groupby('GICS Sector').sum()
#| include: true
#| echo: true
grouped_df['active_weight']=grouped_df['pf_weights']-grouped_df['bm_weights']
print (grouped_df['active_weight'])
#| include: false
#| echo: false
df = pd.read_csv('factors_pf_returns.csv')
#| include: true
#| echo: true
df['correlation_mom']=df['sp500'].rolling(20).corr(df['momentum'])
df['correlation_value']=df['sp500'].rolling(20).corr(df['value'])
#| include: false
#| echo: false
df = pd.read_csv('factors_pf_returns.csv')
#| include: true
#| echo: true
df['correlation_mom']=df['sp500'].rolling(20).corr(df['momentum'])
df['correlation_value']=df['sp500'].rolling(20).corr(df['value'])
#| include: false
#| echo: false
df = pd.read_csv('pf_factors.csv')
#| include: true
#| echo: true
df['correlation_mom']=df['sp500'].rolling(20).corr(df['momentum'])
df['correlation_value']=df['sp500'].rolling(20).corr(df['value'])
#| include: true
#| echo: true
df['correlation_mom']=df['sp500'].rolling(20).corr(df['WML'])
df['correlation_value']=df['sp500'].rolling(20).corr(df['value'])
#| include: true
#| echo: true
df['correlation_mom']=df['sp500'].rolling(20).corr(df['WML'])
df['correlation_value']=df['sp500'].rolling(20).corr(df['value_factor'])
#| include: true
#| echo: true
df['correlation_mom']=df['S&P500'].rolling(20).corr(df['WML'])
df['correlation_value']=df['S&P500'].rolling(20).corr(df['value_factor'])
#| include: true
#| echo: true
df['correlation_mom'].plot()
df['correlation_value'].plot()
plt.legend()
plt.show()
import numpy as np # Load numpy  package
import pandas as pd # Load pandas package
#| include: false
#| echo: false
import matplotlib.pyplot as plt
df = pd.read_csv('pf_factors.csv')
#| include: false
#| echo: false
import matplotlib.pyplot as plt
df = pd.read_csv('pf_factors.csv')
#| include: true
#| echo: true
df['correlation_mom']=df['S&P500'].rolling(20).corr(df['WML'])
df['correlation_value']=df['S&P500'].rolling(20).corr(df['value_factor'])
#| include: true
#| echo: true
df['correlation_mom'].plot()
df['correlation_value'].plot()
plt.legend()
plt.show()
#| include: true
#| echo: true
df['corr_momentum'].plot()
df['corr_value'].plot()
plt.legend()
plt.show()
#| include: false
#| echo: false
import matplotlib.pyplot as plt
df = pd.read_csv('pf_factors.csv')
#| include: true
#| echo: true
df['corr_momentum']=df['S&P500'].rolling(20).corr(df['WML'])
df['corr_value']=df['S&P500'].rolling(20).corr(df['value_factor'])
#| include: true
#| echo: true
df['corr_momentum'].plot()
df['corr_value'].plot()
plt.legend()
plt.show()
#| include: true
#| echo: true
df['corr_momentum'].plot()
df['corr_value'].plot()
plt.legend(loc="best")
plt.show()
#| include: true
#| echo: true
df['corr_momentum'].plot()
df['corr_value'].plot()
plt.legend()
plt.show()
#| include: true
#| echo: true
df['correlation_mom']=df['S&P500'].rolling(20).corr(df['WML'])
df['correlation_value']=df['S&P500'].rolling(20).corr(df['value_factor'])
#| include: true
#| echo: true
df['correlation_mom'].plot()
df['correlation_value'].plot()
plt.legend()
plt.show()
#| include: false
#| echo: false
import matplotlib.pyplot as plt
df = pd.read_csv('pf_factors.csv')
#| include: true
#| echo: true
df['correlation_mom']=df['S&P500'].rolling(20).corr(df['WML'])
df['correlation_value']=df['S&P500'].rolling(20).corr(df['value_factor'])
#| include: true
#| echo: true
df['correlation_mom'].plot()
df['correlation_value'].plot()
plt.legend()
plt.show()
#| include: true
#| echo: true
plt.plot(df['correlation_mom'], label = "momentum")
plt.plot(df['correlation_value'], label = "value")
plt.legend()
plt.show()
#| include: false
#| echo: false
import matplotlib.pyplot as plt
df = pd.read_csv('pf_factors.csv')
#| include: true
#| echo: true
df['correlation_mom']=df['S&P500'].rolling(20).corr(df['WML'])
df['correlation_value']=df['S&P500'].rolling(20).corr(df['value_factor'])
#| include: true
#| echo: true
plt.plot(df['correlation_mom'], label = "momentum")
plt.plot(df['correlation_value'], label = "value")
plt.legend()
plt.show()
#| include: false
#| echo: false
import matplotlib.pyplot as plt
df = pd.read_csv('pf_factors.csv')
#| include: true
#| echo: true
df['correlation_mom']=df['S&P500'].rolling(20).corr(df['WML'])
df['correlation_value']=df['S&P500'].rolling(20).corr(df['value_factor'])
#| include: true
#| echo: true
plt.plot(df['correlation_mom'], label = "momentum")
plt.plot(df['correlation_value'], label = "value")
plt.legend()
plt.show()
#| include: true
#| echo: true
plt.clf()
plt.plot(df['correlation_mom'], label = "momentum")
plt.plot(df['correlation_value'], label = "value")
plt.legend()
plt.show()
#| include: true
#| echo: true
plt.clf()
plt.plot(df['correlation_mom'], label = "momentum")
plt.plot(df['correlation_value'], label = "value")
plt.title("Korelacja między czynnikami ryzyka a stopą zwrotu indeksu S&P500")
plt.legend()
plt.show()
#| include: true
#| echo: true
df.corr()
#| include: true
#| echo: true
factors_data = df["WML", "value_factor", "portfolio"]
#| include: true
#| echo: true
factors_data = df.loc([2,3,4])
#| include: true
#| echo: true
factors_data = df.loc[2,3,4]
#| include: true
#| echo: true
factors_data = df.loc[[2,3,4]]
#| include: false
#| echo: false
factors_data = df.loc[[2,3,4]]
#| include: false
#| echo: false
factor_data = df.loc[[2,3,4]]
#| include: true
#| echo: true
factor_data.corr()
#| include: false
#| echo: false
factor_data = df.loc[[2,3,4]]
#| include: true
#| echo: true
factor_data.head(10)
#| include: false
#| echo: false
factor_data = df[["WML", "value_factor", "portfolio"]]
#| include: true
#| echo: true
factor_data.head(10)
#| include: true
#| echo: true
factor_data.corr()
#| include: true
#| echo: true
factor_data['correlation_value']=factor_data['portfolio'].rolling(5).corr(factor_data['value_factor'])
factor_data['correlation_value'].plot()
plt.legend()
plt.show()
#| include: true
#| echo: true
plt.clf()
factor_data['correlation_value']=factor_data['portfolio'].rolling(5).corr(factor_data['value_factor'])
factor_data['correlation_value'].plot()
plt.legend()
plt.show()
#| include: true
#| echo: true
plt.clf()
factor_data['correlation_value']=factor_data['portfolio'].rolling(5).corr(factor_data['value_factor'])
plt.plot(df["date"], factor_data['correlation_value'])
plt.legend()
plt.show()
#| include: true
#| echo: true
plt.clf()
factor_data['correlation_value']=factor_data['portfolio'].rolling(5).corr(factor_data['value_factor'])
factor_data['correlation_value'].plot()
plt.legend()
plt.show()
## Analiza portfolio względem benchmarku
![](images/port_bench.png)
reticulate::repl_python()
#| include: false
#| echo: false
factor_returns = pd.read_csv('factors_pf_returns.csv')
import numpy as np # Load numpy  package
import pandas as pd # Load pandas package
quit
#| include: false
#| echo: false
library(reticulate)
use_virtualenv("C:/Users/rafal/.virtualenvs/my-python", required = TRUE)
#| include: false
#| echo: false
library(reticulate)
use_virtualenv("C:/Users/rafal/.virtualenvs/my-python", required = TRUE)
#| include: false
#| #| echo: false
#py_install("pandas", envname = "my-python")
#pandas <- import("pandas")
#py_install("jupyter", envname = "my-python")
reticulate::repl_python()
import numpy as np # Load numpy  package
import pandas as pd # Load pandas package
quit
#| include: false
#| echo: false
library(reticulate)
use_virtualenv("C:/Users/rafal/.virtualenvs/my-python", required = TRUE)
reticulate::repl_python()
# Wyświetlenie tabeli
df.style.set_table_styles(
[{'selector': 'table', 'props': [('width', '100%')] }]
)
quit
#| include: false
#| echo: false
library(reticulate)
use_virtualenv("C:/Users/rafal/.virtualenvs/my-python", required = TRUE)
#| include: false
#| echo: false
library(reticulate)
use_virtualenv("C:/Users/rafal/.virtualenvs/my-python", required = TRUE)
library(reticulate)
use_virtualenv("venv", required = TRUE)
# virtualenv_create("venv")
reticulate::repl_python()
